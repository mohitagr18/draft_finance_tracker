{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f5694b",
   "metadata": {},
   "source": [
    "Test NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec9a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from autogen_agentchat.agents import AssistantAgent, CodeExecutorAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from agents.prompts.unstructured_text_parser_message import UNSTRUCTURED_TEXT_PARSER_SYSTEM_MESSAGE\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68355184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads a CSV bank statement, attempts to identify common transaction columns,\n",
    "    and returns the data as a JSON string.\n",
    "\n",
    "    This tool is designed to handle CSV files with common column names like\n",
    "    'Date', 'Transaction', 'Description', 'Amount', 'Credit', 'Debit'.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The local path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string representing a list of transaction dictionaries.\n",
    "             Returns an error message string if parsing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # --- Column Name Identification Logic ---\n",
    "        # Standardize column names to lowercase for easier matching\n",
    "        df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "        # Define potential aliases for our target columns\n",
    "        date_aliases = ['date', 'transaction date']\n",
    "        desc_aliases = ['description', 'transaction', 'details']\n",
    "        amount_aliases = ['amount', 'debit', 'credit']\n",
    "\n",
    "        # Find the actual column names in the DataFrame\n",
    "        date_col = next((col for col in df.columns if col in date_aliases), None)\n",
    "        desc_col = next((col for col in df.columns if col in desc_aliases), None)\n",
    "        \n",
    "        # For amount, we might have separate debit/credit columns\n",
    "        debit_col = next((col for col in df.columns if col == 'debit'), None)\n",
    "        credit_col = next((col for col in df.columns if col == 'credit'), None)\n",
    "        amount_col = next((col for col in df.columns if col == 'amount'), None)\n",
    "\n",
    "        if not date_col or not desc_col:\n",
    "            return json.dumps({\"error\": \"Could not automatically identify date or description columns.\"})\n",
    "\n",
    "        # --- Data Extraction and Formatting ---\n",
    "        transactions = []\n",
    "        for index, row in df.iterrows():\n",
    "            transaction = {\n",
    "                \"date\": row[date_col],\n",
    "                \"description\": row[desc_col],\n",
    "                \"amount\": None\n",
    "            }\n",
    "\n",
    "            # Handle different amount representations\n",
    "            if amount_col:\n",
    "                transaction[\"amount\"] = row[amount_col]\n",
    "            elif debit_col and credit_col:\n",
    "                # Combine debit/credit into a single amount column\n",
    "                # Debits are negative, credits are positive\n",
    "                debit = pd.to_numeric(row[debit_col], errors='coerce') or 0\n",
    "                credit = pd.to_numeric(row[credit_col], errors='coerce') or 0\n",
    "                transaction[\"amount\"] = credit - debit\n",
    "            \n",
    "            if transaction[\"amount\"] is not None:\n",
    "                transactions.append(transaction)\n",
    "\n",
    "        return json.dumps(transactions, indent=2)\n",
    "\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Failed to parse CSV file: {str(e)}\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d96172f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced extract_text_from_pdf function that returns JSON/dict\n",
    "import pypdf\n",
    "import json\n",
    "\n",
    "def extract_text_from_pdf_enhanced(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Enhanced version that extracts text from PDF and returns structured data.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The local path to the PDF file.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing extracted text and metadata.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = pypdf.PdfReader(file_path)\n",
    "        \n",
    "        # Extract text from all pages\n",
    "        full_text = \"\"\n",
    "        pages_data = []\n",
    "        \n",
    "        for page_num, page in enumerate(reader.pages):\n",
    "            page_text = page.extract_text()\n",
    "            full_text += page_text + \"\\n--- End of Page ---\\n\"\n",
    "            \n",
    "            pages_data.append({\n",
    "                \"page_number\": page_num + 1,\n",
    "                \"text\": page_text,\n",
    "                \"text_length\": len(page_text)\n",
    "            })\n",
    "        \n",
    "        # Create structured response\n",
    "        result = {\n",
    "            \"success\": True,\n",
    "            \"file_path\": file_path,\n",
    "            \"total_pages\": len(reader.pages),\n",
    "            \"total_text_length\": len(full_text),\n",
    "            \"full_text\": full_text,\n",
    "            \"pages\": pages_data,\n",
    "            \"metadata\": {\n",
    "                \"extraction_method\": \"pypdf\",\n",
    "                \"file_size_bytes\": len(reader.stream.read()) if hasattr(reader, 'stream') else None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"file_path\": file_path\n",
    "        }\n",
    "\n",
    "# Extract text from PDF with enhanced function\n",
    "pdf_data = extract_text_from_pdf_enhanced('temp/test_statement.pdf')\n",
    "\n",
    "# Print summary\n",
    "if pdf_data[\"success\"]:\n",
    "    print(f\"Successfully extracted text from {pdf_data['total_pages']} pages\")\n",
    "    print(f\"Total text length: {pdf_data['total_text_length']} characters\")\n",
    "    print(f\"File path: {pdf_data['file_path']}\")\n",
    "    print(\"\\nFirst 200 characters of extracted text:\")\n",
    "    print(pdf_data['full_text'][:200])\n",
    "    \n",
    "    # Store the full text for later use\n",
    "    pdf_text = pdf_data['full_text']\n",
    "else:\n",
    "    print(f\"Error extracting text: {pdf_data['error']}\")\n",
    "    pdf_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a6d063",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_csv_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# Now parse the unstructured text using the AI agents\n",
    "import asyncio\n",
    "from tools.parse_unstructured_text import parse_unstructured_text\n",
    "from models.openai_model_client import OpenAIAPIClient\n",
    "from config.docker_util import DockerCodeExecutor\n",
    "\n",
    "# Initialize components\n",
    "model_client = OpenAIAPIClient()\n",
    "code_executor = DockerCodeExecutor()\n",
    "\n",
    "# Parse the PDF text\n",
    "async def parse_pdf():\n",
    "    result = await parse_unstructured_text(pdf_text, model_client, code_executor)\n",
    "    return result\n",
    "\n",
    "# Run the parsing\n",
    "parsed_result = await parse_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eda341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Print the parsing result\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Parse and pretty print the JSON result\n",
    "try:\n",
    "    parsed_data = json.loads(parsed_result)\n",
    "    print(\"Parsed JSON data:\")\n",
    "    print(json.dumps(parsed_data, indent=2))\n",
    "    \n",
    "    # Show summary if it's a list of transactions\n",
    "    if isinstance(parsed_data, list):\n",
    "        print(f\"\\nFound {len(parsed_data)} transactions\")\n",
    "        if len(parsed_data) > 0:\n",
    "            print(\"Sample transaction:\")\n",
    "            print(json.dumps(parsed_data[0], indent=2))\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing JSON: {e}\")\n",
    "    print(\"Raw result:\")\n",
    "    print(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with the JSON/dict output\n",
    "print(\"Full PDF data structure:\")\n",
    "print(json.dumps(pdf_data, indent=2, default=str))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Accessing specific data:\")\n",
    "print(f\"Success: {pdf_data.get('success')}\")\n",
    "print(f\"Total pages: {pdf_data.get('total_pages')}\")\n",
    "print(f\"Text length: {pdf_data.get('total_text_length')}\")\n",
    "\n",
    "# Show page-by-page breakdown\n",
    "if pdf_data.get('pages'):\n",
    "    print(\"\\nPage breakdown:\")\n",
    "    for page in pdf_data['pages']:\n",
    "        print(f\"Page {page['page_number']}: {page['text_length']} characters\")\n",
    "        print(f\"  Preview: {page['text'][:100]}...\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50712372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to JSON string if needed\n",
    "pdf_data_json = json.dumps(pdf_data, indent=2, default=str)\n",
    "print(\"PDF data as JSON string:\")\n",
    "print(pdf_data_json)\n",
    "\n",
    "# You can also save it to a file\n",
    "# with open('pdf_extraction_result.json', 'w') as f:\n",
    "#     json.dump(pdf_data, f, indent=2, default=str)\n",
    "\n",
    "# Or get just the text content as JSON\n",
    "text_only_data = {\n",
    "    \"text\": pdf_data.get('full_text', ''),\n",
    "    \"metadata\": {\n",
    "        \"pages\": pdf_data.get('total_pages', 0),\n",
    "        \"length\": pdf_data.get('total_text_length', 0)\n",
    "    }\n",
    "}\n",
    "text_json = json.dumps(text_only_data, indent=2)\n",
    "print(\"\\nText-only JSON:\")\n",
    "print(text_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0cbd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8e0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8b4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49e72d60",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
