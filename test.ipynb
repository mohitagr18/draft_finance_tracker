{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f5694b",
   "metadata": {},
   "source": [
    "Test NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ec9a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from autogen_agentchat.agents import AssistantAgent, CodeExecutorAgent, UserProxyAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from agents.prompts.unstructured_text_parser_message import UNSTRUCTURED_TEXT_PARSER_SYSTEM_MESSAGE\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import json\n",
    "import pypdf\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7becfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68355184",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdf(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts all text content from a given PDF file.\n",
    "\n",
    "    This tool's purpose is to provide the raw text data from a PDF to an LLM agent.\n",
    "    The agent will then be responsible for writing code to parse this unstructured text.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The local path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: A single string containing all the extracted text from the PDF.\n",
    "             Returns an error message string if extraction fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = pypdf.PdfReader(file_path)\n",
    "        full_text = \"\"\n",
    "        for page in reader.pages:\n",
    "            full_text += page.extract_text() + \"\\n--- End of Page ---\\n\"\n",
    "        return full_text\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text from PDF: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d96172f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_text = extract_text_from_pdf('temp/test_statement2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "def convert_pdfs_in_dir(input_dir: str, output_dir: str = \"temp\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Scans a directory for PDF files, extracts text, and saves each to a text file.\n",
    "\n",
    "    This function searches the specified input directory for any files with a '.pdf'\n",
    "    extension. It then extracts the text from each PDF and saves it to a new file \n",
    "    in the output directory. The output files are named sequentially \n",
    "    (e.g., statement1.txt, statement2.txt).\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): The path to the directory containing the PDF files.\n",
    "        output_dir (str): The name of the directory to save the text files.\n",
    "                          Defaults to 'temp'.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of paths to the newly created text files.\n",
    "                   Returns an empty list if the input directory doesn't exist\n",
    "                   or contains no PDF files.\n",
    "    \"\"\"\n",
    "    # Check if the input directory exists\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"Error: Input directory '{input_dir}' not found.\")\n",
    "        return []\n",
    "\n",
    "    # Find all files in the directory that end with .pdf (case-insensitive)\n",
    "    pdf_files = [\n",
    "        os.path.join(input_dir, filename)\n",
    "        for filename in os.listdir(input_dir)\n",
    "        if filename.lower().endswith(\".pdf\") and os.path.isfile(os.path.join(input_dir, filename))\n",
    "    ]\n",
    "\n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in '{input_dir}'.\")\n",
    "        return []\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    created_text_files = []\n",
    "\n",
    "    # Enumerate through the list of discovered PDFs to process them\n",
    "    for i, file_path in enumerate(pdf_files, start=1):\n",
    "        try:\n",
    "            print(f\"Processing '{file_path}'...\")\n",
    "            reader = pypdf.PdfReader(file_path)\n",
    "            full_text = \"\"\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    full_text += page_text + \"\\n\"\n",
    "            \n",
    "            # Define the output file name and path\n",
    "            output_filename = f\"statement{i}.txt\"\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            \n",
    "            # Write the extracted text to the new file\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(full_text)\n",
    "            \n",
    "            created_text_files.append(output_path)\n",
    "            print(f\"Successfully created '{output_path}'\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "            \n",
    "    return created_text_files\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd06f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"temp\"\n",
    "\n",
    "# Call the function to convert all PDFs in the directory\n",
    "saved_files = convert_pdfs_in_dir(source_directory)\n",
    "\n",
    "print(\"\\n--- Conversion Complete ---\")\n",
    "if saved_files:\n",
    "    print(\"The following text files were created in the 'temp' directory:\")\n",
    "    for file in saved_files:\n",
    "        print(f\"- {file}\")\n",
    "else:\n",
    "    print(\"No files were created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc09da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0cbd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Imports ---\n",
    "# Standard library and Pydantic\n",
    "import os\n",
    "import json\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Core AutoGen components with explicit paths\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_core.tools import Workbench\n",
    "\n",
    "# --- 2. Define the Desired JSON Structure ---\n",
    "# This defines the schema for each individual transaction.\n",
    "class Transaction(BaseModel):\n",
    "    cardholder: str = Field(description=\"The name of the cardholder who made the transaction.\")\n",
    "    sale_date: Optional[str] = Field(description=\"The date the transaction was made, e.g., '07/15'\")\n",
    "    post_date: str = Field(description=\"The date the transaction was posted to the account, e.g., '07/16'\")\n",
    "    description: str = Field(description=\"The description of the transaction\")\n",
    "    transaction_amount: float = Field(description=\"The amount. Debits (purchases) must be negative, credits (payments) must be positive.\")\n",
    "\n",
    "# This is the main structure for the entire statement.\n",
    "class StatementData(BaseModel):\n",
    "    bank_name: str = Field(description=\"The name of the bank or card issuer, e.g., 'Costco Anywhere Visa Card by Citi'\")\n",
    "    transactions: List[Transaction] = Field(description=\"A list of all transactions from the statement\")\n",
    "\n",
    "# --- 3. Create the Python Function (The 'Tool') ---\n",
    "def parse_bank_statement(bank_name: str, transactions: List[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Parses raw bank statement data into a structured JSON format using Pydantic models.\n",
    "    \n",
    "    Args:\n",
    "        bank_name: The name of the bank or card issuer.\n",
    "        transactions: A list of dictionaries, each representing a transaction.\n",
    "                      Each dictionary must contain all fields for the Transaction model.\n",
    "                      \n",
    "    Returns:\n",
    "        A JSON string representation of the structured data.\n",
    "    \"\"\"\n",
    "    statement = StatementData(\n",
    "        bank_name=bank_name,\n",
    "        transactions=[Transaction(**t) for t in transactions]\n",
    "    )\n",
    "    return statement.model_dump_json(indent=2)\n",
    "\n",
    "# --- 4. Configure AutoGen Agents and Environment ---\n",
    "# Ensure your OPENAI_API_KEY is set as an environment variable\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4o\", \n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY2\")\n",
    "    }\n",
    "]\n",
    "\n",
    "# The Workbench manages the tools and execution environment.\n",
    "workbench = Workbench(work_dir=\"coding\", tools=[parse_bank_statement])\n",
    "\n",
    "# The UserProxyAgent acts as the executor.\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"UserProxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    workbench=workbench,\n",
    ")\n",
    "\n",
    "# The AssistantAgent acts as the planner, deciding to use the tool.\n",
    "parser_assistant = AssistantAgent(\n",
    "    name=\"ParserAssistant\",\n",
    "    system_message=\"\"\"You are an expert financial data extractor. Your task is to meticulously analyze the user's text and use the `parse_bank_statement` tool to convert it into a structured JSON format.\n",
    "\n",
    "    CRITICAL INSTRUCTIONS:\n",
    "    1.  **Cardholders:** The statement has multiple cardholders (e.g., MOHIT AGGARWAL, HIMANI SOOD). You MUST associate each transaction with the correct cardholder name it's listed under.\n",
    "    2.  **Transaction Amounts:** You MUST correctly interpret the signs. \n",
    "        -   Purchases are DEBITS and must be represented as **NEGATIVE** numbers.\n",
    "        -   Payments and Credits are CREDITS and must be represented as **POSITIVE** numbers. If a payment is shown as '-$1,041.44', its value is 1041.44.\n",
    "    3.  **Data Focus:** Ignore all summary data, ads, addresses, and page markers. Focus ONLY on the detailed list of transactions.\"\"\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    tools=[parse_bank_statement],\n",
    ")\n",
    "\n",
    "# --- 5. Your Input String is Loaded Here ---\n",
    "pdf_text_string = parsed_text\n",
    "\n",
    "# --- 6. Initiate the Conversation and Print the Final Output ---\n",
    "user_proxy.initiate_chat(\n",
    "    recipient=parser_assistant,\n",
    "    message=f\"Please parse the following bank statement text:\\n\\n{pdf_text_string}\"\n",
    ")\n",
    "\n",
    "final_message = user_proxy.last_message(parser_assistant)\n",
    "final_json_output = final_message.get(\"content\", \"\")\n",
    "\n",
    "print(\"\\n--- Final Parsed JSON Output ---\")\n",
    "print(final_json_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e72d60",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37125765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install (run once)\n",
    "\n",
    "# ---------------------------\n",
    "# Agent + Code-executor demo\n",
    "# ---------------------------\n",
    "import os, asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent, CodeExecutorAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "async def run_parse_v0_7_2(statement_text: str):\n",
    "    # 1) model client used by AssistantAgent\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\", \n",
    "        api_key=os.getenv(\"OPENAI_API_KEY2\")\n",
    "    )\n",
    "\n",
    "    # 2) assistant - this agent will generate parsing code\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        model_client=model_client,\n",
    "        system_message=(\n",
    "            \"You are an expert Python developer. Given a raw multi-line bank statement string, \"\n",
    "            \"produce Python code inside triple-backtick ```python``` blocks that parses the statement \"\n",
    "            \"into a JSON object with keys: account_info, transactions, rewards and also prints a pandas DataFrame \"\n",
    "            \"for transactions. When done, print the JSON and then reply with the single word: TERMINATE\"\n",
    "        ),\n",
    "        reflect_on_tool_use=True,\n",
    "    )\n",
    "\n",
    "    # 3) code executor component (local) â€” start it before using\n",
    "    code_executor = LocalCommandLineCodeExecutor(work_dir=\"coding\")\n",
    "    await code_executor.start()\n",
    "\n",
    "    # 4) code executor *agent* (do NOT pass llm_config)\n",
    "    code_executor_agent = CodeExecutorAgent(\n",
    "        name=\"code_executor\",\n",
    "        code_executor=code_executor,\n",
    "        # optional: model_client=..., approval_func=..., supported_languages=...\n",
    "        approval_func=None,\n",
    "    )\n",
    "\n",
    "    # 5) team: assistant -> code executor (round-robin). Terminate on 'TERMINATE' or after N messages\n",
    "    termination = TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(6)\n",
    "    team = RoundRobinGroupChat(participants=[assistant, code_executor_agent], termination_condition=termination)\n",
    "\n",
    "    # 6) the task: feed the raw statement and ask for JSON + DataFrame\n",
    "    task_msg = TextMessage(\n",
    "        content=(\n",
    "            \"Parse the bank statement below into JSON & a pandas DataFrame. \"\n",
    "            \"Print the JSON first, then print the DataFrame. End your final response with TERMINATE.\\n\\n\"\n",
    "            f\"{statement_text}\"\n",
    "        ),\n",
    "        source=\"user\",\n",
    "    )\n",
    "\n",
    "    # 7) run the team (synchronous top-level via asyncio)\n",
    "    result = await team.run(task=task_msg)\n",
    "    # final model text available as result.chat_message\n",
    "    print(\"===== AGENT FINAL OUTPUT =====\")\n",
    "    print(result.chat_message.content)\n",
    "\n",
    "    # cleanup\n",
    "    await code_executor.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55540ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cfcd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage: replace the string below with your extracted-statement string\n",
    "YOUR_STATEMENT = parsed_text\n",
    "asyncio.run(run_parse_v0_7_2(YOUR_STATEMENT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
